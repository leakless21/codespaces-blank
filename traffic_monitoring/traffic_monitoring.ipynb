{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79595449",
   "metadata": {},
   "source": [
    "# Traffic Monitoring System\n",
    "\n",
    "This notebook allows you to run the Traffic Monitoring System on platforms like Google Colab, Kaggle, or any Jupyter environment. The system can:\n",
    "\n",
    "- **Detect Vehicles in Real-Time**: Spot cars, trucks, and other vehicles in video feeds\n",
    "- **Read License Plates**: Automatically identify and record license plate numbers\n",
    "- **Track Moving Vehicles**: Follow each vehicle as it moves through the video\n",
    "- **Count Traffic**: Count vehicles as they cross a line you define on the screen\n",
    "- **Store Results**: Save all detection data for later analysis\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **Video Ingestion**: Gets frames from your video source\n",
    "2. **Detection**: Uses AI to find vehicles and license plates\n",
    "3. **Tracking**: Keeps track of each vehicle as it moves\n",
    "4. **Counting**: Counts vehicles when they cross your defined line\n",
    "5. **OCR**: Reads license plate text when detected\n",
    "6. **Storage**: Saves results to a database\n",
    "7. **Main Application**: Coordinates all the components and shows results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd70a5",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, let's set up the environment and install all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d80679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're running in Colab or Kaggle and set up environment\n",
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_KAGGLE = 'kaggle' in sys.modules\n",
    "\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "print(f\"Running in Kaggle: {IN_KAGGLE}\")\n",
    "\n",
    "# Check available resources\n",
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "import importlib.metadata  # Using importlib.metadata instead of deprecated pkg_resources\n",
    "try:\n",
    "    import torch\n",
    "    has_torch = True\n",
    "except ImportError:\n",
    "    has_torch = False\n",
    "\n",
    "print(f\"\\nSystem Information:\")\n",
    "print(f\"OS: {platform.platform()}\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"CPU: {psutil.cpu_count(logical=True)} logical cores\")\n",
    "ram_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "print(f\"RAM: {ram_gb:.2f} GB\")\n",
    "\n",
    "# Check for GPU\n",
    "if has_torch:\n",
    "    has_gpu = torch.cuda.is_available()\n",
    "    gpu_name = torch.cuda.get_device_name(0) if has_gpu else \"None\"\n",
    "    print(f\"GPU: {gpu_name} (CUDA Available: {has_gpu})\")\n",
    "elif IN_COLAB:\n",
    "    # Check for GPU in Colab using system commands\n",
    "    gpu_info = !nvidia-smi -L 2>/dev/null || echo \"No GPU found\"\n",
    "    has_gpu = \"No GPU found\" not in gpu_info[0]\n",
    "    print(f\"GPU: {gpu_info[0] if has_gpu else 'None'}\")\n",
    "else:\n",
    "    print(\"GPU: Unknown (torch not installed)\")\n",
    "    has_gpu = False\n",
    "\n",
    "print(\"\\nThis information will help optimize the configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages from requirements.txt\n",
    "if IN_COLAB or IN_KAGGLE:\n",
    "    # Clone the repository first\n",
    "    !git clone https://github.com/leakless21/codespaces-blank.git\n",
    "    # Install dependencies from requirements.txt\n",
    "    if os.path.exists('codespaces-blank/traffic_monitoring/requirements.txt'):\n",
    "        !pip install -r codespaces-blank/traffic_monitoring/requirements.txt\n",
    "    else:\n",
    "        # Fallback to essential packages if requirements.txt not found\n",
    "        print(\"Requirements file not found, installing essential packages directly...\")\n",
    "        !pip install opencv-python-headless numpy ultralytics onnxruntime boxmot easyocr paho-mqtt PyYAML tqdm fastapi uvicorn pydantic sqlalchemy python-dotenv\n",
    "else:\n",
    "    # If running locally and requirements.txt exists\n",
    "    if os.path.exists('requirements.txt'):\n",
    "        !pip install -r requirements.txt\n",
    "    elif os.path.exists('../requirements.txt'):\n",
    "        !pip install -r ../requirements.txt\n",
    "    else:\n",
    "        print(\"requirements.txt not found, installing essential packages...\")\n",
    "        !pip install opencv-python-headless numpy ultralytics onnxruntime boxmot easyocr paho-mqtt PyYAML tqdm fastapi uvicorn pydantic sqlalchemy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025920d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the repository access\n",
    "import os\n",
    "\n",
    "if IN_COLAB or IN_KAGGLE:\n",
    "    print(\"Setting up repository access...\")\n",
    "    # Check if we already cloned the repository\n",
    "    if os.path.exists('codespaces-blank'):\n",
    "        # Set up path to traffic_monitoring\n",
    "        repo_dir = 'codespaces-blank/traffic_monitoring'\n",
    "        if not os.path.exists(repo_dir):\n",
    "            print(f\"Error: Expected directory {repo_dir} not found\")\n",
    "        else:\n",
    "            print(f\"Using existing repository at {repo_dir}\")\n",
    "            # Change to traffic_monitoring directory\n",
    "            os.chdir(repo_dir)\n",
    "    else:\n",
    "        print(\"Repository not found. Please run the installation cell first.\")\n",
    "else:\n",
    "    # Check if we're already in the traffic_monitoring directory\n",
    "    current_dir = os.path.basename(os.getcwd())\n",
    "    if current_dir != 'traffic_monitoring':\n",
    "        # Try to locate traffic_monitoring directory\n",
    "        if os.path.exists('traffic_monitoring'):\n",
    "            os.chdir('traffic_monitoring')\n",
    "            print(f\"Changed to traffic_monitoring directory\")\n",
    "        else:\n",
    "            print(\"Running in local environment, assuming correct directory structure\")\n",
    "    else:\n",
    "        print(\"Already in traffic_monitoring directory\")\n",
    "\n",
    "# Print current directory structure to verify setup\n",
    "print(f\"\\nCurrent working directory: {os.getcwd()}\")\n",
    "print(\"Available files and directories:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa2cc2",
   "metadata": {},
   "source": [
    "## 2. Download and Prepare Models\n",
    "\n",
    "Download the AI models needed for vehicle detection and license plate recognition if they don't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Check if models already exist\n",
    "vehicle_model_path = Path('./models/yolo11s.onnx')\n",
    "plate_model_path = Path('./models/plate_v8n.onnx')\n",
    "\n",
    "if not vehicle_model_path.exists() or not plate_model_path.exists():\n",
    "    print(\"Downloading models...\")\n",
    "    !python utils/download_model.py\n",
    "    print(\"Models downloaded successfully\")\n",
    "else:\n",
    "    print(\"Models already exist, skipping download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943d8fc",
   "metadata": {},
   "source": [
    "## 3. Upload a Video or Use Sample Data\n",
    "\n",
    "Now you can either upload your own video or use one of the sample videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# For Colab: provide an upload widget\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"Please upload a video file:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        video_path = os.path.join('data', filename)\n",
    "        with open(video_path, 'wb') as f:\n",
    "            f.write(uploaded[filename])\n",
    "        print(f\"Uploaded {filename} to {video_path}\")\n",
    "elif IN_KAGGLE:\n",
    "    # For Kaggle: list available input files\n",
    "    print(\"Available input files:\")\n",
    "    !ls ../input\n",
    "    \n",
    "    # Symlink input directory to make files accessible\n",
    "    !ln -s ../input input\n",
    "else:\n",
    "    print(\"Available sample videos:\")\n",
    "    !ls data/*.mp4 data/*.MOV data/*.avi 2>/dev/null || echo \"No sample videos found in data/ directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9643b",
   "metadata": {},
   "source": [
    "## 4. View and Edit Configuration\n",
    "\n",
    "First, let's examine the current configuration. Then we'll set up the counting line to match your specific video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Display the current configuration\n",
    "config_path = 'config/settings/config.yaml'\n",
    "\n",
    "# Ensure the config directory exists\n",
    "os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "\n",
    "# Read and display current config if it exists\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        print(\"Current configuration:\")\n",
    "        print(yaml.dump(config, default_flow_style=False))\n",
    "else:\n",
    "    print(\"No configuration file found. Creating a default configuration.\")\n",
    "    # Create a default configuration\n",
    "    config = {\n",
    "        'video': {\n",
    "            'source': 'data/sample.mp4',  # Will be updated with available video\n",
    "            'frame_skip': 1,\n",
    "            'process_resolution': [640, 480],\n",
    "            'output_fps': 30.0\n",
    "        },\n",
    "        'detection': {\n",
    "            'vehicle_model': 'models/yolo11s.onnx',\n",
    "            'plate_model': 'models/plate_v8n.onnx',\n",
    "            'vehicle_model_version': 'yolo11',\n",
    "            'plate_model_version': 'yolov8',\n",
    "            'confidence': 0.25,\n",
    "            'iou_threshold': 0.45\n",
    "        },\n",
    "        'tracking': {\n",
    "            'tracker_type': 'bytetrack',\n",
    "            'confidence': 0.3\n",
    "        },\n",
    "        'counting': {\n",
    "            'use_relative_coordinates': True,\n",
    "            'line': {\n",
    "                'start': [0.25, 0.6],\n",
    "                'end': [0.75, 0.6]\n",
    "            },\n",
    "            'raw_coordinates': {\n",
    "                'start': [320, 360],\n",
    "                'end': [960, 360]\n",
    "            }\n",
    "        },\n",
    "        'ocr': {\n",
    "            'languages': ['en'],\n",
    "            'use_gpu': False\n",
    "        },\n",
    "        'hardware': {\n",
    "            'use_gpu': False,\n",
    "            'provider': 'auto',\n",
    "            'precision': 'fp32'\n",
    "        },\n",
    "        'storage': {\n",
    "            'database_path': 'data/traffic_data.db',\n",
    "            'save_images': False\n",
    "        },\n",
    "        'mqtt': {\n",
    "            'enabled': False,\n",
    "            'broker': 'localhost',\n",
    "            'port': 1883,\n",
    "            'topic_prefix': 'traffic'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(config_path, 'w') as file:\n",
    "        yaml.dump(config, file, default_flow_style=False)\n",
    "    print(\"Default configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53584bed",
   "metadata": {},
   "source": [
    "## 5. Select Video Source\n",
    "\n",
    "Choose which video to process and update the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available videos\n",
    "import glob\n",
    "\n",
    "# Search for videos in different locations\n",
    "all_videos = []\n",
    "for ext in ['*.mp4', '*.avi', '*.MOV', '*.mkv']:\n",
    "    # Look in data directory\n",
    "    all_videos.extend(glob.glob(os.path.join('data', ext)))\n",
    "    # For Kaggle, look in input directory if exists\n",
    "    if IN_KAGGLE and os.path.exists('input'):\n",
    "        all_videos.extend(glob.glob(os.path.join('input', ext)))\n",
    "        all_videos.extend(glob.glob(os.path.join('input', '*', ext)))\n",
    "\n",
    "print(\"Found videos:\")\n",
    "for i, video in enumerate(all_videos):\n",
    "    print(f\"{i+1}. {video}\")\n",
    "\n",
    "# Allow selection\n",
    "if all_videos:\n",
    "    selection = input(f\"Enter the number of the video to use (1-{len(all_videos)}): \")\n",
    "    try:\n",
    "        idx = int(selection) - 1\n",
    "        if 0 <= idx < len(all_videos):\n",
    "            selected_video = all_videos[idx]\n",
    "            # Update configuration with selected video\n",
    "            with open(config_path, 'r') as file:\n",
    "                config = yaml.safe_load(file)\n",
    "            config['video']['source'] = selected_video\n",
    "            with open(config_path, 'w') as file:\n",
    "                yaml.dump(config, file, default_flow_style=False)\n",
    "            print(f\"Configuration updated to use {selected_video}\")\n",
    "        else:\n",
    "            print(f\"Invalid selection. Please run the cell again.\")\n",
    "    except ValueError:\n",
    "        print(f\"Invalid input. Please run the cell again.\")\n",
    "else:\n",
    "    print(\"No videos found. Please upload a video first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2664fdf",
   "metadata": {},
   "source": [
    "## 6. Set Counting Line for Your Video\n",
    "\n",
    "**Important**: For accurate traffic counting, you need to set a counting line that matches the specific road position in your video. This cannot be done automatically as each video has roads in different positions.\n",
    "\n",
    "You should set the counting line to cross the road perpendicularly to the direction of traffic. Vehicles will be counted when they cross this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26526f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def get_frame_from_video(video_path):\n",
    "    \"\"\"Extract a representative frame from video for counting line setup\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file {video_path} not found\")\n",
    "        return None\n",
    "        \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return None\n",
    "        \n",
    "    # Get video properties\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Video dimensions: {width}x{height} pixels\")\n",
    "    print(f\"Total frames: {frame_count}, FPS: {fps:.2f}\")\n",
    "    \n",
    "    # Jump to ~20% into the video for a better representative frame\n",
    "    target_frame = int(frame_count * 0.2)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)\n",
    "    \n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame from video\")\n",
    "        return None\n",
    "        \n",
    "    return frame, width, height\n",
    "\n",
    "# Load current config to get video source\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "video_path = config['video']['source']\n",
    "print(f\"Getting sample frame from {video_path} to help set counting line...\")\n",
    "\n",
    "# Get a frame from the video\n",
    "result = get_frame_from_video(video_path)\n",
    "if result is None:\n",
    "    print(\"Cannot help set counting line without a valid video frame\")\n",
    "else:\n",
    "    frame, width, height = result\n",
    "    \n",
    "    # Display the frame\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Sample frame from video - Use this to plan your counting line')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show current counting line settings if they exist\n",
    "    use_raw = config.get('counting', {}).get('use_raw_coordinates', True)  # Default to True for raw coordinates\n",
    "    print(f\"Current setting - Use raw coordinates: {use_raw}\")\n",
    "    \n",
    "    if use_raw:\n",
    "        if 'raw_coordinates' in config.get('counting', {}):\n",
    "            start = config['counting']['raw_coordinates']['start']\n",
    "            end = config['counting']['raw_coordinates']['end']\n",
    "            print(f\"Current raw coordinates: start={start}, end={end}\")\n",
    "    else:\n",
    "        if 'normalized_coordinates' in config.get('counting', {}):\n",
    "            start = config['counting']['normalized_coordinates']['start']\n",
    "            end = config['counting']['normalized_coordinates']['end']\n",
    "            print(f\"Current normalized coordinates: start={start}, end={end}\")\n",
    "            # Convert to pixel positions for visualization\n",
    "            raw_start = [int(start[0] * width), int(start[1] * height)]\n",
    "            raw_end = [int(end[0] * width), int(end[1] * height)]\n",
    "            print(f\"Which is equivalent to pixel coordinates: start={raw_start}, end={raw_end}\")\n",
    "    \n",
    "    # Prompt for new counting line coordinates\n",
    "    print(\"\\nNow let's set a counting line that crosses the road in your video\")\n",
    "    print(\"You have two options:\")\n",
    "    print(\"1. Use raw pixel coordinates (exact positions on screen)\")\n",
    "    print(\"2. Use normalized coordinates (0-1 values that work with any video size)\\n\")\n",
    "    \n",
    "    use_raw_input = input(\"Do you want to use raw pixel coordinates? (y/n): \").lower().strip()\n",
    "    use_raw_coordinates = use_raw_input.startswith('y')\n",
    "    \n",
    "    if use_raw_coordinates:\n",
    "        print(f\"\\nEnter raw pixel coordinates (values from 0 to {width} for X, 0 to {height} for Y)\")\n",
    "        start_x = int(input(f\"Enter starting X position (0-{width}): \").strip())\n",
    "        start_y = int(input(f\"Enter starting Y position (0-{height}): \").strip())\n",
    "        end_x = int(input(f\"Enter ending X position (0-{width}): \").strip())\n",
    "        end_y = int(input(f\"Enter ending Y position (0-{height}): \").strip())\n",
    "        \n",
    "        # Save raw coordinates\n",
    "        if 'counting' not in config:\n",
    "            config['counting'] = {}\n",
    "        config['counting']['use_raw_coordinates'] = True\n",
    "        config['counting']['raw_coordinates'] = {\n",
    "            'start': [start_x, start_y],\n",
    "            'end': [end_x, end_y]\n",
    "        }\n",
    "        \n",
    "        # Also calculate and save normalized coordinates for flexibility\n",
    "        norm_start_x = start_x / width\n",
    "        norm_start_y = start_y / height\n",
    "        norm_end_x = end_x / width\n",
    "        norm_end_y = end_y / height\n",
    "        config['counting']['normalized_coordinates'] = {\n",
    "            'start': [norm_start_x, norm_start_y],\n",
    "            'end': [norm_end_x, norm_end_y]\n",
    "        }\n",
    "    else:\n",
    "        print(\"\\nEnter normalized coordinates (values from 0 to 1, where 0.5 is the middle)\")\n",
    "        norm_start_x = float(input(\"Enter starting X position (0-1): \").strip())\n",
    "        norm_start_y = float(input(\"Enter starting Y position (0-1): \").strip())\n",
    "        norm_end_x = float(input(\"Enter ending X position (0-1): \").strip())\n",
    "        norm_end_y = float(input(\"Enter ending Y position (0-1): \").strip())\n",
    "        \n",
    "        # Save normalized coordinates\n",
    "        if 'counting' not in config:\n",
    "            config['counting'] = {}\n",
    "        config['counting']['use_raw_coordinates'] = False\n",
    "        config['counting']['normalized_coordinates'] = {\n",
    "            'start': [norm_start_x, norm_start_y],\n",
    "            'end': [norm_end_x, norm_end_y]\n",
    "        }\n",
    "        \n",
    "        # Also calculate and save raw coordinates for visualization\n",
    "        start_x = int(norm_start_x * width)\n",
    "        start_y = int(norm_start_y * height)\n",
    "        end_x = int(norm_end_x * width)\n",
    "        end_y = int(norm_end_y * height)\n",
    "        config['counting']['raw_coordinates'] = {\n",
    "            'start': [start_x, start_y],\n",
    "            'end': [end_x, end_y]\n",
    "        }\n",
    "    \n",
    "    # Save the updated config\n",
    "    with open(config_path, 'w') as file:\n",
    "        yaml.dump(config, file, default_flow_style=False)\n",
    "        \n",
    "    # Display the frame with the counting line\n",
    "    line_frame = frame.copy()\n",
    "    cv2.line(line_frame, \n",
    "             (start_x, start_y), \n",
    "             (end_x, end_y), \n",
    "             (0, 0, 255), 2)\n",
    "             \n",
    "    # Add text labels  \n",
    "    cv2.putText(line_frame, \"Counting Line\", (start_x + 10, start_y - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(line_frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Video frame with your counting line')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCounting line has been set successfully!\")\n",
    "    if use_raw_coordinates:\n",
    "        print(f\"Raw coordinates: start=[{start_x}, {start_y}], end=[{end_x}, {end_y}]\")\n",
    "        print(f\"Equivalent normalized: start=[{norm_start_x:.2f}, {norm_start_y:.2f}], end=[{norm_end_x:.2f}, {norm_end_y:.2f}]\")\n",
    "    else:\n",
    "        print(f\"Normalized coordinates: start=[{norm_start_x:.2f}, {norm_start_y:.2f}], end=[{norm_end_x:.2f}, {norm_end_y:.2f}]\")\n",
    "        print(f\"Equivalent raw: start=[{start_x}, {start_y}], end=[{end_x}, {end_y}]\")\n",
    "    print(\"\\nVehicles will be counted when they cross this line.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c62cc",
   "metadata": {},
   "source": [
    "## 6. Edit Configuration (Optional)\n",
    "\n",
    "You can manually adjust various settings to customize how the system works. Add, remove, or modify entries as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76420f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current config\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Configure for NVIDIA GPU usage if available\n",
    "# Update GPU configuration based on system detection\n",
    "if has_gpu:\n",
    "    print(\"NVIDIA GPU detected! Enabling GPU acceleration for all components.\")\n",
    "    # Enable GPU for all components\n",
    "    config['hardware']['use_gpu'] = True\n",
    "    config['hardware']['provider'] = 'CUDAExecutionProvider'\n",
    "    config['hardware']['precision'] = 'fp16'  # Use half precision for better performance\n",
    "    # Enable GPU for OCR as well\n",
    "    config['ocr']['use_gpu'] = True\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU for processing.\")\n",
    "    config['hardware']['use_gpu'] = False\n",
    "    config['hardware']['provider'] = 'CPUExecutionProvider'\n",
    "    config['ocr']['use_gpu'] = False\n",
    "\n",
    "# Set video processing parameters\n",
    "config['video']['frame_skip'] = 1  # Process every frame (2 would process every other frame)\n",
    "config['detection']['confidence'] = 0.25  # Lower = more detections but more false positives\n",
    "\n",
    "# Save the updated config\n",
    "with open(config_path, 'w') as file:\n",
    "    yaml.dump(config, file, default_flow_style=False)\n",
    "\n",
    "print(\"Configuration updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920dc78",
   "metadata": {},
   "source": [
    "## 7. Run Traffic Monitoring System\n",
    "\n",
    "Now let's run the traffic monitoring system using the main.py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Get output directory path for recordings\n",
    "output_dir = Path('data/recordings')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate a timestamp for the output file\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = str(output_dir / f\"traffic_monitoring_{timestamp}.mp4\")\n",
    "\n",
    "print(f\"Will save output to: {output_file}\")\n",
    "\n",
    "# Run main.py with arguments\n",
    "if IN_COLAB or IN_KAGGLE:\n",
    "    # In Colab/Kaggle, we need to run in headless mode (no UI) and just record\n",
    "    cmd = [sys.executable, 'main.py', '--no-ui', '--record', f'--output={output_file}']\n",
    "else:\n",
    "    # If running locally, show UI and also record\n",
    "    cmd = [sys.executable, 'main.py', '--record', f'--output={output_file}']\n",
    "\n",
    "print(f\"Running command: {' '.join(cmd)}\")\n",
    "\n",
    "# Execute the command\n",
    "try:\n",
    "    # Run the process and capture output\n",
    "    process = subprocess.Popen(\n",
    "        cmd, \n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    # Print output in real-time\n",
    "    print(\"Process started. Output:\")\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "        \n",
    "    # Wait for process to complete\n",
    "    process.wait()\n",
    "    print(f\"Process completed with return code: {process.returncode}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nProcess interrupted by user.\")\n",
    "    # Try to terminate the process gracefully\n",
    "    process.terminate()\n",
    "    try:\n",
    "        process.wait(timeout=5)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        process.kill()\n",
    "except Exception as e:\n",
    "    print(f\"Error running traffic monitoring: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e708a",
   "metadata": {},
   "source": [
    "## 8. Display Results\n",
    "\n",
    "Let's display the output video and provide download options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "\n",
    "# Function to create HTML video player for notebook\n",
    "def display_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video data\n",
    "    video_data = open(video_path, 'rb').read()\n",
    "    \n",
    "    # Encode as base64\n",
    "    video_base64 = b64encode(video_data).decode('utf-8')\n",
    "    \n",
    "    # Create HTML with video player\n",
    "    html = f'''\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center;\">\n",
    "        <h3>Processed Video: {os.path.basename(video_path)}</h3>\n",
    "        <video width=\"640\" height=\"480\" controls>\n",
    "            <source src=\"data:video/mp4;base64,{video_base64}\" type=\"video/mp4\">\n",
    "            Your browser does not support the video tag.\n",
    "        </video>\n",
    "    </div>\n",
    "    '''\n",
    "    \n",
    "    # Display the video\n",
    "    display(HTML(html))\n",
    "\n",
    "# Find and display the most recent output video\n",
    "output_videos = glob.glob('data/recordings/*.mp4')\n",
    "\n",
    "if output_videos:\n",
    "    # Sort by modification time to get the most recent\n",
    "    latest_video = max(output_videos, key=os.path.getmtime)\n",
    "    print(f\"Displaying most recent output video: {latest_video}\")\n",
    "    display_video(latest_video)\n",
    "    \n",
    "    # Provide download link for Colab users\n",
    "    if IN_COLAB:\n",
    "        from google.colab import files\n",
    "        print(\"\\nDownload the processed video:\")\n",
    "        files.download(latest_video)\n",
    "else:\n",
    "    print(\"No output videos found. The processing may have failed or been interrupted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e1169",
   "metadata": {},
   "source": [
    "## 9. Analyze Results from Database\n",
    "\n",
    "Optionally, let's explore the data collected in the SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce345d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to the database\n",
    "db_path = 'data/traffic_data.db'\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        \n",
    "        # Get table names\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(\"Database tables:\")\n",
    "        for table in tables:\n",
    "            print(f\"- {table[0]}\")\n",
    "            \n",
    "        # Query vehicle counts\n",
    "        df_counts = pd.read_sql(\"SELECT * FROM vehicle_counts ORDER BY timestamp DESC LIMIT 100\", conn)\n",
    "        if not df_counts.empty:\n",
    "            print(f\"\\nVehicle counts (most recent {len(df_counts)} records):\")\n",
    "            display(df_counts.head())\n",
    "            \n",
    "            # Plot counts over time if data exists\n",
    "            if len(df_counts) > 1:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(df_counts['timestamp'], df_counts['count'], marker='o')\n",
    "                plt.title('Vehicle Counts Over Time')\n",
    "                plt.xlabel('Timestamp')\n",
    "                plt.ylabel('Count')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        \n",
    "        # Query license plates\n",
    "        df_plates = pd.read_sql(\"SELECT * FROM license_plates ORDER BY timestamp DESC LIMIT 100\", conn)\n",
    "        if not df_plates.empty:\n",
    "            print(f\"\\nDetected license plates (most recent {len(df_plates)} records):\")\n",
    "            display(df_plates.head())\n",
    "            \n",
    "        # Close connection\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing database: {e}\")\n",
    "else:\n",
    "    print(f\"Database file not found: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db0d14",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "You've successfully run the Traffic Monitoring System! Here's what we accomplished:\n",
    "\n",
    "1. Set up the necessary environment\n",
    "2. Downloaded the required AI models\n",
    "3. Configured the system by directly updating the config.yaml file\n",
    "4. Processed a video to detect, track, count vehicles and read license plates\n",
    "5. Saved and analyzed the results\n",
    "\n",
    "This approach is more efficient as it leverages the existing main.py infrastructure rather than reimplementing functionality in the notebook.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different videos and configurations\n",
    "- Explore the database in more detail for advanced analytics\n",
    "- If you're interested in the technical details, explore the source code in the repository"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
